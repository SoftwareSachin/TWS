"""empty message

Revision ID: 6218212f0a26
Revises: 13a0cdba8b43
Create Date: 2025-06-02 09:54:41.516621

"""
from alembic import op
import sqlalchemy as sa
import sqlalchemy_utils
import sqlmodel # added


# revision identifiers, used by Alembic.
revision = '6218212f0a26'
down_revision = '13a0cdba8b43'
branch_labels = None
depends_on = None


def upgrade():
    op.execute("CREATE EXTENSION IF NOT EXISTS pg_trgm") 
    # ### commands auto generated by Alembic - please adjust! ###

     # Check if the enum types already exist and create them only if they don't
    conn = op.get_bind()
    
    # Check for documenttypeenum
    result = conn.execute(sa.text("SELECT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'documenttypeenum')")).scalar()
    if not result:
        # Create the enum type if it doesn't exist
        op.execute(sa.text("CREATE TYPE documenttypeenum AS ENUM ('Image', 'Audio', 'Video', 'Pdf')"))
    op.execute("ALTER TYPE documenttypeenum ADD VALUE IF NOT EXISTS 'Pdf'")
    
    
    # Check for chunktypeenum
    result = conn.execute(sa.text("SELECT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'chunktypeenum')")).scalar()
    if not result:
        # Create the enum type if it doesn't exist
        op.execute(sa.text("CREATE TYPE chunktypeenum AS ENUM ('ImageDescription' , 'ImageText', 'ImageObject', 'AudioSegment', 'Speaker', 'VideoScene', 'PdfText', 'PdfTable')"))
    op.execute("ALTER TYPE chunktypeenum ADD VALUE IF NOT EXISTS 'PdfText'")
    op.execute("ALTER TYPE chunktypeenum ADD VALUE IF NOT EXISTS 'PdfTable'")



    # Check for documentprocessingstatusenum
    result = conn.execute(sa.text("SELECT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'documentprocessingstatusenum')")).scalar()
    if not result:
        # Create the enum type if it doesn't exist
        op.execute(sa.text("CREATE TYPE documentprocessingstatusenum AS ENUM ('Queued', 'Processing', 'Extracting',' ExtractionCompleted', 'AnalysisCompleted', 'Success', 'Failed', 'Exception', 'Splitting', 'Not_Started')"))
    op.execute("ALTER TYPE documentprocessingstatusenum ADD VALUE IF NOT EXISTS 'Splitting'")
    op.execute("ALTER TYPE documentprocessingstatusenum ADD VALUE IF NOT EXISTS 'Not_Started'")


    op.add_column('datasets', sa.Column('ingestion_status', sqlmodel.sql.sqltypes.AutoString(), nullable=True))
    op.add_column('datasets', sa.Column('ingestion_stats', sa.JSON(), nullable=True))
    op.add_column('datasets', sa.Column('ingestion_last_updated', sa.DateTime(), nullable=True))
    op.add_column('document_chunks', sa.Column('split_id', sqlmodel.sql.sqltypes.GUID(), nullable=True))
    op.create_index(op.f('ix_document_chunks_split_id'), 'document_chunks', ['split_id'], unique=False)
    op.create_foreign_key('fk_document_chunks_split_id', 'document_chunks', 'file_splits', ['split_id'], ['id'])
    op.add_column('documents', sa.Column('name', sqlmodel.sql.sqltypes.AutoString(), nullable=True))
    op.add_column('documents', sa.Column('is_split_document', sa.Boolean(), nullable=True))
    op.add_column('documents', sa.Column('successful_splits_count', sa.Integer(), nullable=True))
    op.add_column('documents', sa.Column('total_splits_count', sa.Integer(), nullable=True))
    op.create_foreign_key('fk_documents_file_id', 'documents', 'files', ['file_id'], ['id'])
    op.add_column('file_splits', sa.Column('document_id', sqlmodel.sql.sqltypes.GUID(), nullable=True))
    op.add_column('file_splits', sa.Column('split_metadata', sa.JSON(), nullable=True))
    op.alter_column('file_splits', 'file_ingestion_id',
               existing_type=sa.UUID(),
               nullable=True)
    op.create_foreign_key('fk_file_splits_document_id', 'file_splits', 'documents', ['document_id'], ['id'])
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('fk_file_splits_document_id', 'file_splits', type_='foreignkey')
    op.alter_column('file_splits', 'file_ingestion_id',
               existing_type=sa.UUID(),
               nullable=False)
    op.drop_column('file_splits', 'split_metadata')
    op.drop_column('file_splits', 'document_id')
    op.drop_constraint('fk_documents_file_id', 'documents', type_='foreignkey')
    op.drop_column('documents', 'total_splits_count')
    op.drop_column('documents', 'successful_splits_count')
    op.drop_column('documents', 'is_split_document')
    op.drop_column('documents', 'name')
    op.drop_constraint('fk_document_chunks_split_id', 'document_chunks', type_='foreignkey')
    op.drop_index(op.f('ix_document_chunks_split_id'), table_name='document_chunks')
    op.drop_column('document_chunks', 'split_id')
    op.drop_column('datasets', 'ingestion_last_updated')
    op.drop_column('datasets', 'ingestion_stats')
    op.drop_column('datasets', 'ingestion_status')
    # ### end Alembic commands ###
