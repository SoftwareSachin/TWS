version: '3.8'

services:
  database:
    build:
      dockerfile: database.Dockerfile
    container_name: database
    restart: always
    env_file: .env
    user: root
    volumes:
      - db_docker:/bitnami/postgresql
      - ./create-dbs.sql:/docker-entrypoint-initdb.d/create-dbs.sql
    ports:
      - "5454:5432" # Remove this on production
    expose:
      - 5432
    environment:
      - POSTGRESQL_USERNAME=${DATABASE_USER}
      - POSTGRESQL_PASSWORD=${DATABASE_PASSWORD}
      - POSTGRESQL_DATABASE=${DATABASE_NAME}

  fastapi_server:
    container_name: fastapi_server
    build: ./backend
    restart: always
    command: "sh -c 'alembic upgrade head && uvicorn app.main:app --reload --loop asyncio --workers 3 --host 0.0.0.0 --port 8000'"
    #command: "sh -c 'alembic upgrade head && gunicorn -w 3 -k uvicorn.workers.UvicornWorker app.main:app  --bind 0.0.0.0:8000 --preload --log-level=debug --timeout 120'"
    volumes:
      - ./backend/app:/code
#      - ./sample_files:/mnt/sample_files
    expose:
      - 8000
    env_file: ".env"
    depends_on:
      - database
    links:
      - caddy_reverse_proxy:storage.localhost

  vault:
    image: hashicorp/vault:1.17
    cap_add:
      - IPC_LOCK
    environment:
      VAULT_ADDR: "https://vault.yourcompany.com:8200"
      VAULT_LOCAL_CONFIG: |
        storage "file" {
          path = "/vault/file"
        }
        listener "tcp" {
          address     = "0.0.0.0:8200"
          tls_disable = 1
        }
        disable_mlock = true
        ui = true
    ports:
      - "8200:8200"
    volumes:
      - C:/vault/config/vault.hcl:/vault/config/vault.hcl
      - C:/vault/data:/vault/data
    command: vault server -config=/vault/config/vault.hcl

    
  redis_server:
    image: redis:alpine
    container_name: redis_server
    restart: always
    env_file: .env
    expose:
      - 6379

  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq_dev
    ports:
      - "5672:5672"  # RabbitMQ main port
      - "15672:15672"  # RabbitMQ management UI port
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq

  celery_worker:
    container_name: celery_worker
    env_file: .env
    restart: always
    build: ./backend
    command: "watchfiles 'celery -A app.be_core.celery worker --pool=threads -Q ingestion_queue -l info'" #
    volumes:
      - ./backend/app:/code
      - ./sample_files:/mnt/sample_files
    # - "${EB_LOG_BASE_DIR}/php-app:/var/log/celery"
    depends_on:
      - database
      - rabbitmq
#      - redis_server


  celery_beat:   #Good for crontab and schedule tasks
    container_name: celery_beat
    restart: always
    env_file: .env
    build:
      context: ./backend
      args:
        INSTALL_DEV: ${INSTALL_DEV-false}
    command: celery -A app.be_core.celery beat -l info -S sqlalchemy_celery_beat.schedulers:DatabaseScheduler -l info
    volumes:
      - ./backend/app:/code
    # - "${EB_LOG_BASE_DIR}/php-app:/var/log/celery-beat"
    depends_on:
      - database
      - rabbitmq
#      - redis_server

  caddy_reverse_proxy:
    container_name: caddy_reverse_proxy
    image: caddy:alpine
    restart: always
    ports:
      - "80:80"
      - "443:443"
    environment:
      - EXT_ENDPOINT1=${EXT_ENDPOINT1}
      - LOCAL_1=${LOCAL_1}
      - LOCAL_2=${LOCAL_2}
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile
      - ./static:/code/static
      - caddy_data:/data
      - caddy_config:/config


volumes:
  db_docker:
  caddy_data:
  caddy_config:
  rabbitmq_data:

